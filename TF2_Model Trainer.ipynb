{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<h1><b>PROJECT HELPING HANDS Model Training</b></h1>\n","\n","Members:\n","1.   Renmar Balana................Leading Developer / Project Manager\n","2.   Xania Shane Oropesa......Full Stack Developer\n","3.   Hewey James Lita...........Tester / Front End Developer\n","4.   Jan Lance Borrero...........Frontend Developer, UI/UX designer\n","5.   Jiggy Brondial..................Data Gathering / Cleaning\n","\n","*BSCS 3-A (2022-2023)*\n","\n","---"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## **ROADMAP TO CREATING AN OBJECT DETECTION TFLITE MODEL**\n","\n","\n","* Collect the dataset of images and label them to get their xml files.\n","\n","* Install the TensorFlow Object Detection API.\n","\n","* Generate the TFRecord files required for training. (need generate_tfrecord.py script and csv files for this)\n","\n","* Edit the model pipeline config file and download the pre-trained model checkpoint.\n","\n","* Train and evaluate the model.\n","\n","* Export and convert the model into TFlite(TensorFlow Lite) format.\n","\n","* Deploy the TFlite model on Android / iOS / IoT devices.\n","\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# **0) Checking Prerequisites**\n","\n","At the time of testing, this notebook works with tensorflow version 2.12, and Python version 3.9.16. \n","If the current version of python does not work, try changing to alternative python versions by running the code below."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!python --version\n","!sudo update-alternatives --config python3"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!sudo apt install python3-pip"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# **1) Import Libraries**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","import glob\n","import xml.etree.ElementTree as ET\n","import pandas as pd\n","import tensorflow as tf\n","print(tf.__version__)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# **2) Create *`customTF2`*, *`training`* and *`data`* folders in your google drive**\n","Create a folder named ***customTF2*** in your google drive.\n","\n","Create another folder named ***training*** inside the ***customTF2*** folder\n","(***training*** folder is where the checkpoints will be saved during training)\n","\n","Create another folder named ***data*** inside the ***customTF2*** folder."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# **3) Create and upload your image files and xml files.**\n"," Create a folder named ***images*** for your custom dataset images and create another folder named ***annotations*** for its corresponding xml files.\n"," \n"," Next, create their zip files and upload them to the ***customTF2*** folder in your drive.\n","\n"," \n"," (Make sure all the image files have extension as \".jpg\" only.\n"," Other formats like \".png\" , \".jpeg\" or even \".JPG\" will give errors since the generate_tfrecord and xml_to_csv scripts here have only \".jpg\" in them)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Collect Images Dataset and label them to get their PASCAL_VOC XML annotations\n","For Datasets, you can check out my Dataset Sources at the bottom of this article in the credits section. You can use any software for labeling like the labelImg tool.\n","\n","Read this [article](https://viso.ai/computer-vision/labelimg-for-image-annotation/) to know more about collecting datasets and labeling process."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# **4) Upload the *`generate_tfrecord.py`* file to the *`customTF2`* folder on your drive.**\n","\n","\n","You can find the generate_tfrecord.py file [here](https://github.com/techzizou/Train-Object-Detection-Model-TF-2.x)\n","\n","# **5) Mount drive and link your folder**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","# this creates a symbolic link so that now the path /content/gdrive/My\\ Drive/ is equal to /mydrive\n","!ln -s /content/gdrive/My\\ Drive/ /mydrive\n","!ls /mydrive"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# **6) Clone the tensorflow models git repository & Install TensorFlow Object Detection API**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# clone the tensorflow models on the colab cloud vm\n","!git clone --q https://github.com/tensorflow/models.git\n","\n","#navigate to /models/research folder to compile protos\n","%cd models/research\n","\n","# Compile protos.\n","!protoc object_detection/protos/*.proto --python_out=.\n","\n","# Install TensorFlow Object Detection API.\n","!cp object_detection/packages/tf2/setup.py .\n","!python -m pip install ."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# **7) Test the model builder**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# testing the model builder to make sure all the required componenets are present.\n","!python object_detection/builders/model_builder_tf2_test.py"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# **8) Navigate to /mydrive/customTF2/data/ and Unzip the *images.zip* and *annotations.zip* files into the *data* folder**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%cd /mydrive/customTF2/data/\n","\n","# unzip the datasets and their contents so that they are now in /mydrive/customTF2/data/ folder\n","!unzip /mydrive/customTF2/images.zip -d .\n","!unzip /mydrive/customTF2/annotations.zip -d ."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# **9) Create test_labels & train_labels**\n","Current working directory is /mydrive/customTF2/data/\n","\n","Divide annotations into test_labels(20%) and train_labels(80%)."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%cd /mydrive/customTF2/data/\n","\n","#creating two dir for training and testing\n","!mkdir test_labels train_labels\n","\n","# lists the files inside 'annotations' in a random order (not really random, by their hash value instead)\n","# Moves the first 271/1355 labels (20% of the labels) to the testing dir: `test_labels`\n","!ls annotations/* | sort -R | head -271 | xargs -I{} mv {} test_labels/\n","\n","\n","# Moves the rest of the labels ( 1084 labels ) to the training dir: `train_labels`\n","!ls annotations/* | xargs -I{} mv {} train_labels/"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Current working directory at this point\n","\n","![alt text](assets/cwd0.png \"Working Directory at this point\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# **10) Create the CSV files and the \"label_map.pbtxt\" file**\n","\n","Current working directory is /mydrive/customTF2/data/\n","\n","Run this xml_to_csv script below to create ***test_labels.csv*** and ***train_labels.csv***\n","\n","This also creates the ***label_map.pbtxt*** file using the classes mentioned in the xml files. "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%cd /mydrive/customTF2/data/\n","\n","#adjusted from: https://github.com/datitran/raccoon_dataset\n","def xml_to_csv(path):\n","  classes_names = []\n","  xml_list = []\n","\n","  for xml_file in glob.glob(path + '/*.xml'):\n","    tree = ET.parse(xml_file)\n","    root = tree.getroot()\n","    for member in root.findall('object'):\n","      classes_names.append(member[0].text)\n","      print(root.find('filename').text)\n","      #print(int(root .find(\"object\").find(\"bndbox\").find(\"xmin\").text))\n","      #print(int(root.find('object/bndbox/xmin').text))\n","      value = (root.find('filename').text  ,\n","               int(root.find('size')[0].text),\n","               int(root.find('size')[1].text),\n","               member[0].text,\n","               int(root.find('object/bndbox/xmin').text),\n","               int(root.find('object/bndbox/ymin').text),\n","               int(root.find('object/bndbox/xmax').text),\n","               int(root.find('object/bndbox/ymax').text))\n","      xml_list.append(value)\n","  column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n","  xml_df = pd.DataFrame(xml_list, columns=column_name) \n","  classes_names = list(set(classes_names))\n","  classes_names.sort()\n","  return xml_df, classes_names\n","\n","for label_path in ['train_labels', 'test_labels']:\n","  image_path = os.path.join(os.getcwd(), label_path)\n","  xml_df, classes = xml_to_csv(label_path)\n","  xml_df.to_csv(f'{label_path}.csv', index=None)\n","  print(f'Successfully converted {label_path} xml to csv.')\n","\n","label_map_path = os.path.join(\"label_map.pbtxt\")\n","pbtxt_content = \"\"\n","\n","for i, class_name in enumerate(classes):\n","    pbtxt_content = (\n","        pbtxt_content\n","        + \"item {{\\n    id: {0}\\n    name: '{1}'\\n}}\\n\\n\".format(i + 1, class_name)\n","    )\n","pbtxt_content = pbtxt_content.strip()\n","with open(label_map_path, \"w\") as f:\n","    f.write(pbtxt_content)\n","    print('Successfully created label_map.pbtxt ')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Directory after step 10\n","\n","![alt text](assets/cwd2.png \"Directory after step 10\")"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[{"file_id":"1BV5VLNX5Ivc0jruOB01oHcuufxX0Y5fp","timestamp":1686026317148},{"file_id":"1dF4H3E2cSdirhOrrGh8d0pW5la9MKmoR","timestamp":1683790974598},{"file_id":"1vJzjx2UT3qTwpU6dpA2gHV4LjdhyZpoU","timestamp":1682051935215},{"file_id":"16KNzz9ez5wYFFKIgmtWb3qdXJlvov1yQ","timestamp":1680022478789},{"file_id":"13SPNsogGr8o4KQvBAxJBBCIonUx5Xad8","timestamp":1671921180995},{"file_id":"1IV6wvOXVJBoP2BlyU5XA33LTWAgkHX-y","timestamp":1636485394082}]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}

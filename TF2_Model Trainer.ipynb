{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<h1><b>PROJECT HELPING HANDS Model Training</b></h1>\n","\n","Members:\n","1.   Renmar Balana................Leading Developer / Project Manager\n","2.   Xania Shane Oropesa......Full Stack Developer\n","3.   Hewey James Lita...........Tester / Front End Developer\n","4.   Jan Lance Borrero...........Frontend Developer, UI/UX designer\n","5.   Jiggy Brondial..................Data Gathering / Cleaning\n","\n","*BSCS 3-A (2022-2023)*\n","\n","---"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## **ROADMAP TO CREATING AN OBJECT DETECTION TFLITE MODEL**\n","\n","\n","* Collect the dataset of images and label them to get their xml files.\n","\n","* Install the TensorFlow Object Detection API.\n","\n","* Generate the TFRecord files required for training. (need generate_tfrecord.py script and csv files for this)\n","\n","* Edit the model pipeline config file and download the pre-trained model checkpoint.\n","\n","* Train and evaluate the model.\n","\n","* Export and convert the model into TFlite(TensorFlow Lite) format.\n","\n","* Deploy the TFlite model on Android / iOS / IoT devices.\n","\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# **0) Checking Prerequisites**\n","\n","At the time of testing, this notebook works with tensorflow version 2.12, and Python version 3.9.16. \n","If the current version of python does not work, try changing to alternative python versions by running the code below."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!python --version\n","!sudo update-alternatives --config python3"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!sudo apt install python3-pip"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# **1) Import Libraries**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","import glob\n","import xml.etree.ElementTree as ET\n","import pandas as pd\n","import tensorflow as tf\n","print(tf.__version__)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# **2) Create *`customTF2`*, *`training`* and *`data`* folders in your google drive**\n","Create a folder named ***customTF2*** in your google drive.\n","\n","Create another folder named ***training*** inside the ***customTF2*** folder\n","(***training*** folder is where the checkpoints will be saved during training)\n","\n","Create another folder named ***data*** inside the ***customTF2*** folder."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# **3) Create and upload your image files and xml files.**\n"," Create a folder named ***images*** for your custom dataset images and create another folder named ***annotations*** for its corresponding xml files.\n"," \n"," Next, create their zip files and upload them to the ***customTF2*** folder in your drive.\n","\n"," \n"," (Make sure all the image files have extension as \".jpg\" only.\n"," Other formats like \".png\" , \".jpeg\" or even \".JPG\" will give errors since the generate_tfrecord and xml_to_csv scripts here have only \".jpg\" in them)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Collect Images Dataset and label them to get their PASCAL_VOC XML annotations\n","For Datasets, you can check out my Dataset Sources at the bottom of this article in the credits section. You can use any software for labeling like the labelImg tool.\n","\n","Read this [article](https://viso.ai/computer-vision/labelimg-for-image-annotation/) to know more about collecting datasets and labeling process."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# **4) Upload the *`generate_tfrecord.py`* file to the *`customTF2`* folder on your drive.**\n","\n","\n","You can find the generate_tfrecord.py file [here](https://github.com/techzizou/Train-Object-Detection-Model-TF-2.x)\n","\n","# **5) Mount drive and link your folder**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","# this creates a symbolic link so that now the path /content/gdrive/My\\ Drive/ is equal to /mydrive\n","!ln -s /content/gdrive/My\\ Drive/ /mydrive\n","!ls /mydrive"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[{"file_id":"1BV5VLNX5Ivc0jruOB01oHcuufxX0Y5fp","timestamp":1686026317148},{"file_id":"1dF4H3E2cSdirhOrrGh8d0pW5la9MKmoR","timestamp":1683790974598},{"file_id":"1vJzjx2UT3qTwpU6dpA2gHV4LjdhyZpoU","timestamp":1682051935215},{"file_id":"16KNzz9ez5wYFFKIgmtWb3qdXJlvov1yQ","timestamp":1680022478789},{"file_id":"13SPNsogGr8o4KQvBAxJBBCIonUx5Xad8","timestamp":1671921180995},{"file_id":"1IV6wvOXVJBoP2BlyU5XA33LTWAgkHX-y","timestamp":1636485394082}]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}
